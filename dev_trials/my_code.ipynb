{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   FlightDate                                    Airline Origin Dest  \\\n",
      "0  2022-04-04  Commutair Aka Champlain Enterprises, Inc.    GJT  DEN   \n",
      "1  2022-04-04  Commutair Aka Champlain Enterprises, Inc.    HRL  IAH   \n",
      "2  2022-04-04  Commutair Aka Champlain Enterprises, Inc.    DRO  DEN   \n",
      "3  2022-04-04  Commutair Aka Champlain Enterprises, Inc.    IAH  GPT   \n",
      "4  2022-04-04  Commutair Aka Champlain Enterprises, Inc.    DRO  DEN   \n",
      "\n",
      "   Cancelled  Diverted  CRSDepTime  DepTime  DepDelayMinutes  DepDelay  ...  \\\n",
      "0      False     False        1133   1123.0              0.0     -10.0  ...   \n",
      "1      False     False         732    728.0              0.0      -4.0  ...   \n",
      "2      False     False        1529   1514.0              0.0     -15.0  ...   \n",
      "3      False     False        1435   1430.0              0.0      -5.0  ...   \n",
      "4      False     False        1135   1135.0              0.0       0.0  ...   \n",
      "\n",
      "   WheelsOff  WheelsOn  TaxiIn  CRSArrTime  ArrDelay  ArrDel15  \\\n",
      "0     1140.0    1220.0     8.0        1245     -17.0       0.0   \n",
      "1      744.0     839.0     9.0         849      -1.0       0.0   \n",
      "2     1535.0    1622.0    14.0        1639      -3.0       0.0   \n",
      "3     1446.0    1543.0     4.0        1605     -18.0       0.0   \n",
      "4     1154.0    1243.0     8.0        1245       6.0       0.0   \n",
      "\n",
      "   ArrivalDelayGroups  ArrTimeBlk  DistanceGroup  DivAirportLandings  \n",
      "0                -2.0   1200-1259              1                   0  \n",
      "1                -1.0   0800-0859              2                   0  \n",
      "2                -1.0   1600-1659              2                   0  \n",
      "3                -2.0   1600-1659              2                   0  \n",
      "4                 0.0   1200-1259              2                   0  \n",
      "\n",
      "[5 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'Combined_Flights_2022.csv'  # Replace with your dataset path\n",
    "df = pd.read_csv(file_path)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns if any\n",
    "columns_to_drop = [\n",
    "    'FlightDate', 'Tail_Number', 'Operated_or_Branded_Code_Share_Partners',\n",
    "    'OriginStateName', 'DestStateName', 'OriginCityName', 'DestCityName'\n",
    "]\n",
    "df = df.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "# Handling Missing Values\n",
    "df = df.ffill()  # forward fill as an example, adjust as needed\n",
    "\n",
    "# Optional: Subset data for testing (e.g., use 10% of data for faster model training)\n",
    "df = df.sample(frac=0.2, random_state=42)  # Adjust fraction to balance time and performance\n",
    "\n",
    "# One-Hot Encode all categorical columns\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "df = pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Feature Engineering: Create a target column\n",
    "df['Delay'] = df['DepDelayMinutes'].apply(lambda x: 1 if x > 15 else 0)\n",
    "df = df.drop(['DepDelayMinutes', 'ArrDelayMinutes'], axis=1)\n",
    "\n",
    "# Split into features and target\n",
    "X = df.drop('Delay', axis=1)\n",
    "y = df['Delay']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scale numeric features only\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Airline', 'Origin', 'Dest', 'Marketing_Airline_Network',\n",
      "       'IATA_Code_Marketing_Airline', 'Operating_Airline',\n",
      "       'IATA_Code_Operating_Airline', 'OriginState', 'DestState', 'DepTimeBlk',\n",
      "       'ArrTimeBlk'],\n",
      "      dtype='object')\n",
      "         Cancelled  Diverted  CRSDepTime  DepTime  DepDelay  ArrTime  AirTime  \\\n",
      "3811797      False     False        1831   1826.0      -5.0   1923.0     31.0   \n",
      "615029       False     False        1605   1605.0       0.0   1812.0    194.0   \n",
      "3228533      False     False        1719   1714.0      -5.0   2052.0    314.0   \n",
      "3129490      False     False        1515   1533.0      18.0   2302.0    251.0   \n",
      "1273418      False     False         715    709.0      -6.0    837.0     73.0   \n",
      "\n",
      "         CRSElapsedTime  ActualElapsedTime  Distance  ...  \\\n",
      "3811797            62.0               57.0     125.0  ...   \n",
      "615029            212.0              247.0    1162.0  ...   \n",
      "3228533           330.0              338.0    2486.0  ...   \n",
      "3129490           260.0              269.0    2106.0  ...   \n",
      "1273418            98.0               88.0     501.0  ...   \n",
      "\n",
      "         ArrTimeBlk_1500-1559  ArrTimeBlk_1600-1659  ArrTimeBlk_1700-1759  \\\n",
      "3811797                 False                 False                 False   \n",
      "615029                  False                 False                  True   \n",
      "3228533                 False                 False                 False   \n",
      "3129490                 False                 False                 False   \n",
      "1273418                 False                 False                 False   \n",
      "\n",
      "         ArrTimeBlk_1800-1859  ArrTimeBlk_1900-1959  ArrTimeBlk_2000-2059  \\\n",
      "3811797                 False                  True                 False   \n",
      "615029                  False                 False                 False   \n",
      "3228533                 False                 False                  True   \n",
      "3129490                 False                 False                 False   \n",
      "1273418                 False                 False                 False   \n",
      "\n",
      "         ArrTimeBlk_2100-2159  ArrTimeBlk_2200-2259  ArrTimeBlk_2300-2359  \\\n",
      "3811797                 False                 False                 False   \n",
      "615029                  False                 False                 False   \n",
      "3228533                 False                 False                 False   \n",
      "3129490                 False                  True                 False   \n",
      "1273418                 False                 False                 False   \n",
      "\n",
      "         Delay  \n",
      "3811797      0  \n",
      "615029       0  \n",
      "3228533      0  \n",
      "3129490      1  \n",
      "1273418      0  \n",
      "\n",
      "[5 rows x 1007 columns]\n"
     ]
    }
   ],
   "source": [
    "print(categorical_columns)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# # Define the parameter grid\n",
    "# param_grid_rf = {\n",
    "#     'n_estimators': [50],         # Start with fewer trees\n",
    "#     'max_depth': [10],            # Limit tree depth to control complexity\n",
    "#     'class_weight': ['balanced']\n",
    "# }\n",
    "\n",
    "# rf = RandomForestClassifier(random_state=42, n_jobs=-1)  # Use all CPU cores\n",
    "# grid_rf = GridSearchCV(rf, param_grid_rf, scoring='f1', cv=5)\n",
    "# grid_rf.fit(X_train, y_train)\n",
    "# # \n",
    "# # Retrieve the best estimator\n",
    "# best_rf = grid_rf.best_estimator_\n",
    "# print(\"Best parameters for Random Forest:\", grid_rf.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated F1 scores: [0.9929949  0.98868282 0.98620656]\n",
      "Average F1 score: 0.989294757924104\n",
      "Confusion Matrix:\n",
      " [[190561   1319]\n",
      " [     0  52820]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00    191880\n",
      "           1       0.98      1.00      0.99     52820\n",
      "\n",
      "    accuracy                           0.99    244700\n",
      "   macro avg       0.99      1.00      0.99    244700\n",
      "weighted avg       0.99      0.99      0.99    244700\n",
      "\n",
      "AUC-ROC Score: 0.9998102345614375\n",
      "Top 10 Important Features:\n",
      "                  Feature  Importance\n",
      "30  DepartureDelayGroups    0.326621\n",
      "29              DepDel15    0.165277\n",
      "36              ArrDelay    0.121037\n",
      "4               DepDelay    0.104191\n",
      "38    ArrivalDelayGroups    0.098288\n",
      "37              ArrDel15    0.082403\n",
      "32             WheelsOff    0.015200\n",
      "5                ArrTime    0.012642\n",
      "2             CRSDepTime    0.011004\n",
      "3                DepTime    0.010100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Using the best parameters found initially: {'class_weight': 'balanced', 'max_depth': 10, 'n_estimators': 50}\n",
    "rf_model = RandomForestClassifier(class_weight='balanced', max_depth=10, n_estimators=30, random_state=42)\n",
    "cv_scores = cross_val_score(rf_model, X_train, y_train, cv=3, scoring='f1')\n",
    "print(\"Cross-validated F1 scores:\", cv_scores)\n",
    "print(\"Average F1 score:\", cv_scores.mean())\n",
    "\n",
    "# Step 3: Train Final Model on Larger Data with Best Parameters\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and Probabilities\n",
    "y_pred = rf_model.predict(X_test)\n",
    "y_prob = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Model Evaluation\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"AUC-ROC Score:\", roc_auc_score(y_test, y_prob))\n",
    "\n",
    "# Step 4: Feature Importance Analysis\n",
    "importances = rf_model.feature_importances_\n",
    "feature_names = X.columns\n",
    "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display top 10 features\n",
    "print(\"Top 10 Important Features:\\n\", feature_importance_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aishwaryadevi/Library/Python/3.10/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:07:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[191880      0]\n",
      " [     0  52820]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    191880\n",
      "           1       1.00      1.00      1.00     52820\n",
      "\n",
      "    accuracy                           1.00    244700\n",
      "   macro avg       1.00      1.00      1.00    244700\n",
      "weighted avg       1.00      1.00      1.00    244700\n",
      "\n",
      "AUC-ROC Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Initialize XGBoost classifier\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Train the model without early stopping\n",
    "xgb.fit(X_train, y_train, verbose=True)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix_xgb = confusion_matrix(y_test, y_pred_xgb)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix_xgb)\n",
    "\n",
    "# Classification Report\n",
    "class_report_xgb = classification_report(y_test, y_pred_xgb)\n",
    "print(\"Classification Report:\\n\", class_report_xgb)\n",
    "\n",
    "# AUC-ROC Score\n",
    "roc_auc_xgb = roc_auc_score(y_test, xgb.predict_proba(X_test)[:, 1])\n",
    "print(\"AUC-ROC Score:\", roc_auc_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aishwaryadevi/Library/Python/3.10/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:12:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/aishwaryadevi/Library/Python/3.10/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:12:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/aishwaryadevi/Library/Python/3.10/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:12:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/aishwaryadevi/Library/Python/3.10/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:12:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/aishwaryadevi/Library/Python/3.10/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:12:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated Accuracy scores: [1. 1. 1. 1. 1.]\n",
      "Cross-validated ROC AUC scores: [1. 1. 1. 1. 1.]\n",
      "Cross-validated F1 scores: [1. 1. 1. 1. 1.]\n",
      "Average Accuracy: 1.0\n",
      "Average ROC AUC: 1.0\n",
      "Average F1 score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Define the cross-validation strategy (e.g., 5-fold stratified cross-validation)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define scoring metrics for cross-validation\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'roc_auc': 'roc_auc',\n",
    "    'f1': 'f1'\n",
    "}\n",
    "\n",
    "# Perform cross-validation with multiple scoring metrics\n",
    "cv_results = cross_validate(xgb, X, y, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "\n",
    "# Print cross-validated scores\n",
    "print(\"Cross-validated Accuracy scores:\", cv_results['test_accuracy'])\n",
    "print(\"Cross-validated ROC AUC scores:\", cv_results['test_roc_auc'])\n",
    "print(\"Cross-validated F1 scores:\", cv_results['test_f1'])\n",
    "print(\"Average Accuracy:\", cv_results['test_accuracy'].mean())\n",
    "print(\"Average ROC AUC:\", cv_results['test_roc_auc'].mean())\n",
    "print(\"Average F1 score:\", cv_results['test_f1'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated Accuracy scores: [1. 1. 1. 1. 1.]\n",
      "Cross-validated ROC AUC scores: [1. 1. 1. 1. 1.]\n",
      "Cross-validated F1 scores: [1. 1. 1. 1. 1.]\n",
      "Average Accuracy: 1.0\n",
      "Average ROC AUC: 1.0\n",
      "Average F1 score: 1.0\n",
      "Confusion Matrix:\n",
      " [[191880      0]\n",
      " [ 52662    158]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88    191880\n",
      "           1       1.00      0.00      0.01     52820\n",
      "\n",
      "    accuracy                           0.78    244700\n",
      "   macro avg       0.89      0.50      0.44    244700\n",
      "weighted avg       0.83      0.78      0.69    244700\n",
      "\n",
      "AUC-ROC Score: 0.5041177584248391\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "xgb = XGBClassifier(eval_metric='logloss')  # 'eval_metric' set to 'logloss' for binary classification\n",
    "\n",
    "# Define the cross-validation strategy\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define scoring metrics for cross-validation\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'roc_auc': 'roc_auc',\n",
    "    'f1': 'f1'\n",
    "}\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_results = cross_validate(xgb, X, y, cv=cv, scoring=scoring, n_jobs=-1, return_train_score=True)\n",
    "\n",
    "# Print cross-validated scores\n",
    "print(\"Cross-validated Accuracy scores:\", cv_results['test_accuracy'])\n",
    "print(\"Cross-validated ROC AUC scores:\", cv_results['test_roc_auc'])\n",
    "print(\"Cross-validated F1 scores:\", cv_results['test_f1'])\n",
    "print(\"Average Accuracy:\", cv_results['test_accuracy'].mean())\n",
    "print(\"Average ROC AUC:\", cv_results['test_roc_auc'].mean())\n",
    "print(\"Average F1 score:\", cv_results['test_f1'].mean())\n",
    "\n",
    "# Fit the model on the entire training set\n",
    "xgb.fit(X, y)\n",
    "\n",
    "# Predict on the test set (replace X_test with your test data if separate)\n",
    "y_pred = xgb.predict(X_test)\n",
    "y_pred_proba = xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate and display additional evaluation metrics\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", classification_rep)\n",
    "\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "print(\"AUC-ROC Score:\", auc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aishwaryadevi/Library/Python/3.10/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:22:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[191880      0]\n",
      " [     0  52820]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    191880\n",
      "           1       1.00      1.00      1.00     52820\n",
      "\n",
      "    accuracy                           1.00    244700\n",
      "   macro avg       1.00      1.00      1.00    244700\n",
      "weighted avg       1.00      1.00      1.00    244700\n",
      "\n",
      "AUC-ROC Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "# Instantiate XGBClassifier\n",
    "xgb = XGBClassifier(\n",
    "    scale_pos_weight=191880/52820,  # Adjust for class imbalance\n",
    "    use_label_encoder=False,  # Suppress unnecessary warning\n",
    "    eval_metric='logloss'     # Set evaluation metric\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and Evaluation\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "y_proba_xgb = xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_xgb))\n",
    "\n",
    "# Classification Report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_xgb))\n",
    "\n",
    "# AUC-ROC Score\n",
    "roc_auc = roc_auc_score(y_test, y_proba_xgb)\n",
    "print(\"AUC-ROC Score:\", roc_auc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
